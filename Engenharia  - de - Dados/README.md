# 📊 Pirâmide de Estudo para se Tornar um Engenheiro de Dados

## 🏛️ Visão Geral da Pirâmide

```plaintext
       🔺 NÍVEL 5 – Data Engineer Profissional (TOPO)
      ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
     ┃ Pipelines em produção, Cloud  ┃
     ┃ e orquestração avançada       ┃
      ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
       🔺 NÍVEL 4 – Pipelines e Cloud
      ┏━━━━━━━━━━━━━━━━━━━━━┓
     ┃ Airflow, Spark, AWS/GCP ┃
     ┃ Deploy e escalabilidade ┃
      ┗━━━━━━━━━━━━━━━━━━━━━┛
       🔺 NÍVEL 3 – ETL e Banco de Dados
      ┏━━━━━━━━━━━━━━━━━━━━━┓
     ┃ Extração, transformação ┃
     ┃ PostgreSQL, MongoDB     ┃
      ┗━━━━━━━━━━━━━━━━━━━━━┛
       🔺 NÍVEL 2 – Python para Dados
      ┏━━━━━━━━━━━━━━━━━━━━━┓
     ┃ Pandas, NumPy, APIs     ┃
     ┃ Automação com scripts   ┃
      ┗━━━━━━━━━━━━━━━━━━━━━┛
       🔺 NÍVEL 1 – Lógica e Fundamentos (BASE)
      ┏━━━━━━━━━━━━━━━━━━━━━┓
     ┃ Lógica de programação,  ┃
     ┃ Git, terminal, SQL básico ┃
      ┗━━━━━━━━━━━━━━━━━━━━━┛
```

---

## 🔻 NÍVEL 1 – Lógica e Fundamentos

### 📚 Estude:
- Lógica com Python
- Git + GitHub
- Terminal (Linux básico)
- SQL básico (SELECT, WHERE, JOIN)

### 💡 Projetos:
- Scripts para organização de arquivos
- Consultas SQL simples com SQLite

---

## 🔻 NÍVEL 2 – Python para Dados

### 📚 Estude:
- Pandas (dataframes, filtros, agregações)
- NumPy (arrays e cálculos)
- Leitura de CSV, Excel, JSON
- Requisições com `requests` e APIs
- Automatização com scripts

### 💡 Projetos:
- Análise de dados com CSV (ex: dados de vendas)
- Consumo de API pública (clima, moedas)
- Relatórios automáticos com Python

---

## 🔻 NÍVEL 3 – ETL e Banco de Dados

### 📚 Estude:
- Conceito de ETL (Extract, Transform, Load)
- PostgreSQL (CRUD, joins, views)
- MongoDB (NoSQL, coleções, filtros)
- SQL avançado (CTEs, índices)

### 💡 Projetos:
- Pipeline simples que extrai dados de API, transforma com Pandas e insere no PostgreSQL
- Conector entre arquivos `.csv` e banco

---

## 🔻 NÍVEL 4 – Pipelines e Cloud

### 📚 Estude:
- Apache Airflow (orquestração de pipelines)
- Spark (processamento de dados em larga escala)
- AWS (S3, Glue, Redshift) ou GCP (BigQuery, Cloud Storage)
- Docker para empacotamento

### 💡 Projetos:
- Pipeline Airflow com DAG diária
- Uso de Docker para subir script de ETL
- Spark para processar grandes volumes

---

## 🔻 NÍVEL 5 – Engenheiro de Dados Profissional (TOPO)

### 📚 Estude:
- Data Lakes e Data Warehouses
- Arquitetura de dados em nuvem
- Segurança e performance
- Infraestrutura como código (Terraform básico)
- Testes e CI/CD para dados

### 💡 Projetos:
- Projeto completo com ingestão → transformação → análise em Cloud
- Monitoramento e logging de pipeline

---

## ✅ Dicas Finais:

- Prefira **Python** para automatização e scripts de dados
- Use **GitHub** como portfólio
- Faça **projetos pequenos e consistentes**
- Anote tudo no **Notion, Obsidian ou Trello**
